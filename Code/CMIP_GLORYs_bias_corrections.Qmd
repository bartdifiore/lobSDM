---
title: "CMIP-GLORYs Bias Correciton"
author: "Andrew Allyn + Adam Kemberling"
description: | 
  Seasonal Bias Correction of CMIP6 Experiments using GLORYs Climatologies
date: "Updated on: `r Sys.Date()`"
format: 
  html:
    code-fold: true
    code-tools: true
    df-print: kable
    self-contained: true
execute: 
  echo: true
  warning: false
  message: true
  fig.align: "center"
  comment: ""
params: 
  experiment: 
      label: "Select CMIP experiment"
      value: "ssp5_85"
      input: select
      choices: ["ssp1_26", "ssp5_85"]
  climate_start: "1993"
  climate_stop: "2023"
---

```{r setup, include=FALSE}

###__ Packages  ####
library(here)
library(ncdf4)
library(RNetCDF)
library(raster)
library(janitor)
library(gmRi)
library(patchwork)
library(tidyverse)
library(knitr)

# Load the build code and stratification function
res_path    <- cs_path("RES_Data")
cmip_path   <- cs_path("RES_Data", "CMIP6")
glorys_file <- paste0(res_path, "GLORYs/NW_Atl_MonthlyTemps/Climatology1993to2024.nc")

#### Set theme  ####
theme_set(theme_minimal())

#  color palette for quick raster displays
temp_pal <- rev(RColorBrewer::brewer.pal(n = 10, name = "RdBu"))

####  Functions  ####
source(here::here("Code/sdm_workflow_funs.R"))

experiment <- params$experiment
cmip_date_key <- cmip_date_key_fun(experiment)
```


`r use_gmri_style_rmd(css_file = "gmri_rmarkdown.css")`


## Load CMIP6 Data for sea surface Temperature

 
The only variable we will use OISSTv2 data to bias correct for is sea surface temperature.



```{r load collection}

####  Choose a variable
pick_var <- "bot_temp"
experiment <- "ssp5_85"

# Load all the CMIP Scenarios - cropped to study area
cmip_data <- import_cmip_collection(
  cmip_var = pick_var, 
  experiment = experiment,
  grid = "GlorysGrid")
```




### Match Dates to Xarray

Sometimes the raster package has an issue with the dates used by the climate models, more specifically how its a non-standard calendar without leap years. These are "cftimes", and don't match standard date-parsing tools.

Xarray doesn't really have an issue for some reason, so this step matches the file to what the dates should be based on how they appear in xarray. This ensures proper date comparisons down the line.

The date keys (key to match cftimes from xarray based on cmip6 model run ID) are made in `date_keys.py`. A short python script that opens each dataset and stores the dates with the model ID as a lookup table.

```{r get layer names}

# Debugging for glorys adaptation

# # Problem: names all carry the regridding prefix stgrid_
# names(cmip_date_key$bot_temp$future_projections)
# 
# # Not finding the dates in date_key, date_key was made with stGrid_ files 
# # works with swap_stgrid modification
# get_cmip_dates(
#       cmip_source = names(cmip_data)[[1]], 
#       cmip_var = pick_var,
#       time_dim = dim(cmip_data[[1]])[3], 
#       swap_stgrid = TRUE
# )
# 
# 
# # Can we insert this into the function?
# str_replace(names(cmip_data)[[1]], "GlorysGrid_", "stGrid_")
# 
# # yes
# cmip_date_key[[pick_var]]$future_projections[[str_replace(names(cmip_data)[[1]], "GlorysGrid_", "stGrid_")]]



# # New Bug: GlorysGrid_thetao_MRI-ESM2-0_r1i1p1f1_ssp585
# # Time index length from date key does not match
# # Caused by error in `names<-`:
# # ! incorrect number of layer names
# 
# # This one is an over-shoot
# length(names(cmip_data$`GlorysGrid_thetao_MRI-ESM2-0_r1i1p1f1_ssp585`))
# 
# # It should look like this
# length(names(cmip_data$GlorysGrid_thetao_NESM3_r1i1p1f1_ssp585))
# 
# # We could quick-fix it by rsubsetting times 1:length(names(whatever))
# # But only if its shorter, if its longer we need to subset


# --- end debug






# Get the cftime dates from the date key - this ensures proper date matching
# the fallback is to assign year and month generally based on if its an historic run or not
cmip_data <- imap(
  .x = cmip_data, 
  .f = function(cmip_dataset, cmip_source){
    
    # Progress Report
    message(paste("Setting Names for: ", cmip_source))
    
    # If it's too long, and we know it goes to 2300... Subset through 2100
    # ex. GlorysGrid_thetao_MRI-ESM2-0_r1i1p1f1_ssp585
    if(length(names(cmip_dataset)) == 3432){
      message(print("Subsetting on time dimension through 2100"))
      cmip_dataset <- cmip_dataset[[1:1032]]
    }
    
  # Get the names from the lookup key
    names_from_xarray <- get_cmip_dates(
      cmip_source = cmip_source, 
      cmip_var = pick_var,
      time_dim = dim(cmip_dataset)[3],
      swap_stgrid = TRUE)
    
    # Assign them:
    names(cmip_dataset) <- names_from_xarray
    
  return(cmip_dataset)})

```



```{r}
# Plot something
test_slice <- cmip_data[[1]][[1]]
plot(
  test_slice,
  main = str_c(
    "Single Month of CMIP6 Data\n", 
    names(cmip_data)[1],"\n", 
    pick_var,": ",names(test_slice)),
  col = temp_pal)
```


### Screening Strange Values

There is the possibility that in some data sources or different raster layers within them that values that are exceptionally high or low may be used in place of an explicit `NA`. 

These will cause issues when we look across models to get summary metrics. This step screens them for extreme fill values using the `raster::clamp` function.


```{r}
# Checking min and max values

# # can use clamp to set limits around plausible values
# clamp_test <- clamp(cmip_data[[1]], lower = -50, upper = 100, useValues = FALSE)


# # This one, is it all NA's? seems like it
# plot(cmip_data[["GlorysGrid_thetao_FIO-ESM-2-0_r1i1p1f1_ssp585"]][[1]])



cmip_data <- imap(cmip_data, function(ras_brick, ras_lab){ 
  message(paste0("Screening:  ", ras_lab))
  max_val <- max(raster::values(ras_brick), na.rm = T)
  min_val <- min(raster::values(ras_brick), na.rm = T)
  message(paste0(pick_var, "| Min val: ", round(min_val), ", Max Val: ", round(max_val)))
  if(max_val == -Inf & min_val == Inf){
    message(paste(ras_lab, " values empty, returning NULL"))
    ras_brick <- NULL}
  # Do the clamp?
  # Boiling water seems like a reasonable limit
  #ras_brick <- clamp(ras_brick, lower = -50, upper = 100, useValues = FALSE) 
  return(ras_brick)
})



```

### Build Lookup Table of Historic and Projected Climate Runs

The CMIP to anomalies function relies on a consistent naming structure of XYYYYMMDD to pull out the correct years and months. If this isn't the case the function as currently written will break.

This table is also used to match climatologies to their historic periods.

```{r name structure table}
#####  Build table of name structure and length dimension and file source type


#### 1. Get the start and end time dimensions that R gives
tdims <- map_dfr(cmip_data, function(cmip_stack){
    # Pull out some descriptive aspects of each
    # Assemble as a table
    time_dims  <- dim(cmip_stack)[3]
    summary_table <- data.frame( "time_dim"  = time_dims)}
    # collapse to dataframe
    , .id = "file_name")



#### 2. Do some formatting and rearranging to label historic etc.
tdims <- tdims %>%
  mutate(
    scenario_type = ifelse(str_detect(file_name, "historic"), "historic", "projection"),
    cmip_scenario = ifelse(str_detect(file_name, "historic"),
                           str_remove(file_name, "_historical"),
                           str_remove(file_name, "_ssp...")),
    nc_name = paste0(file_name, ".nc")) %>% 
  select(cmip_scenario, scenario_type, time_dim, file_name, nc_name)

# The code digging into the dates is no longer relevant, just need the scenario type info
name_structure <- tdims
```


**Need two things now:**

 1. CMIP6 Climatology for the variables we loaded

The `cmip_to_clim` function will take the CMIP6 data for a given model, subset it to a desired range of years, and compute a monthly climatological average for that period.
 
 2. The corresponding anomalies

Once we have the climatologies, we can compute respective monthly anomalies from that climatological period. This is done in the next step with `cmip_get_anomalies`

## Build CMIP Climatologies

As mentioned above, each CMIP6 model will have its own monthly climatology. These are computed in the following cell.


```{r}

# Set start and end year for climatology 
# start_year <- params$climate_start
start_year <- 1993

# end_year <- params$climate_stop
end_year<- 2023


# Determine which netcdf files cover the reference period and should be used for the climatologies
historic_runs <- which(str_detect(names(cmip_data), "historic"))


# Run the climatologies for the historic runs only
cmip_clims <- imap(
  .x = cmip_data[historic_runs],
  .f = function(cmip_stack, cmip_name){
  
  # Get monthly climatology
  message(paste0("Processing Climatology: ", cmip_name))
  cmip_clim <- suppressMessages(
    cmip_to_clim(
      cmip_stack = cmip_stack, 
      clim_years = c(start_year, end_year)))
  
  # return the climatology (should work b/c smaller)
  return(cmip_clim)})


```



```{r}
plot(cmip_clims[[1]][[1]],
     main = "Single Month of a CMIP6 Climatology",
     col = temp_pal)
```



## Get CMIP Scenario Anomalies (deltas)

Now the climatologies are matched up with the correct data sets to get anomalies for both the historic periods as well as the matching climate projections.


```{r get cmip anomalies}
cmip_anoms <- imap(cmip_data, function(cmip_data, cmip_name){
  
  # Check for those trouble files
  if(class(cmip_clims) == "character"){
    return("Problem with CMIP Naming Structure")}
  
  
  # Identify root cmip file & its number in the list
  cmip_root <- str_replace(cmip_name, "_ssp...", "_historical")
  clim_id <- which(names(cmip_clims) == cmip_root)
  
  # # Get the matching climatology
  if(length(clim_id) != 0){
    
    # Grab the climatology
    clim_use <- cmip_clims[[clim_id]]

    # print progress
    message(paste0(cmip_name, " has matching climatology, processing anomalies."))
    
    # Use sdm_workflow function to match months and return anomalies
    cmip_anomalies <- cmip_get_anomalies(cmip_data, clim_use)
    return(cmip_anomalies)
    
  } else if(length(clim_id) == 0) {
    message(paste0("No matching climate reference for: ", cmip_name))
    cmip_anomalies <- "ugly duckling"
    return(cmip_anomalies)}
  
})

# Pull out the cases without historical matches
no_matches <- which(map_chr(cmip_anoms, class) == "character")
good_data <- which(names(cmip_anoms) %not in% names(no_matches))

# and subset
cmip_anoms <- cmip_anoms[good_data]

# clean up memory
rm(cmip_data)
```


```{r}
# Plot Check
plot(cmip_anoms[[1]][[1]], 
     main = "Single Month of CMIP6 Anomalies",
     col = temp_pal)
```

##  GLORYs Bias Correction

In order to do this we need the climatology for each of those variables for a reference period that aligns with the CMIP historical data


### Import GLORYs Climatology

The GLORYs climatology was processed using xarray in the `GLORYs_CLimatology.ipynb` in this repo. We can load it and then get the SST and BT as individual files.
```{r import ref climatology}
# Load GLORYs Climatology
nc_open(paste0(cs_path("RES_Data"), "/GLORYs/NW_Atl_MonthlyTemps/Climatology1993to2023.nc"))
glorys_clim <- raster::stack(cs_path("RES_Data", "GLORYs/NW_Atl_MonthlyTemps/Climatology1993to2023.nc"))

# Split it out into a sst and bt file
glorys_clim_sst <- stack(paste0(cs_path("RES_Data"), "/GLORYs/NW_Atl_MonthlyTemps/Climatology1993to2023.nc"), varname = "surf_temp")

glorys_clim_bt <- stack(paste0(cs_path("RES_Data"), "/GLORYs/NW_Atl_MonthlyTemps/Climatology1993to2023.nc"), varname = "bot_temp")
  
# Select based on experiment
if(pick_var == "surf_temp"){
  glorys_clim_use<- glorys_clim_sst
} else {
  glorys_clim_use<- glorys_clim_bt
}
```

```{r}
# Plot Check
plot(glorys_clim_use[[1]], 
     col = temp_pal, 
     main = "January Climatology")
```

### Bias Correction
Resample anomalies first, as needed first
```{r resample CMIP anomalies}
cmip_anoms <- map(cmip_anoms, function(anom_grid) {
  if (class(anom_grid) == "character") {
    return("Problem with CMIP Naming Structure")
  }
  resample_grid(starting_grid = anom_grid, desired_grid = glorys_clim_use[[1]])
})
```

This is the step where the anomalies/deltas from each CMIP6 run are applied to the climatology of the reference data climatology.

```{r perform bias correction}

####  Match and Bias Correct
cmip_anoms_bcorrect <- map(cmip_anoms, function(anom_grid) {
  # check for problem data
  if (class(anom_grid) == "character") {
    return("Problem with CMIP Naming Structure")
  }

  # run for data that passes check
  delta_method_bias_correct(
    cmip_grid = anom_grid,
    reference_climatology = glorys_clim_use
  )
})

# remove regular anomalies
rm(cmip_anoms)
```

```{r}
# Single Run
plot(cmip_anoms_bcorrect[[1]][[1]],
  main = "Single Month of Bias Corrected Data",
  col = temp_pal
)
```

## Processing Mean/5th/95th

The following code sets up the sub-setting and matching components to process comparable model runs. Since the historical period and future projections cover different periods, they get run separately here, to be combined again after different data representing across-model quantiles have been pulled from them.

```{r quantile setup}

####  Different Treatments for Historical / Projections

# Get the names for historic and future runs
historic_names     <- filter(name_structure, scenario_type == "historic") %>% pull(file_name)
projection_names   <- filter(name_structure, scenario_type == "projection") %>% pull(file_name)

# Their matching index numbers
historic_sources   <- which(names(cmip_anoms_bcorrect) %in% historic_names)
projection_sources <- which(names(cmip_anoms_bcorrect) %in% projection_names)

# Use those to separate the two groups
historic_bias_corr   <- cmip_anoms_bcorrect[historic_sources]
projection_bias_corr <- cmip_anoms_bcorrect[projection_sources]

# Will need a year-month key for all the time steps for historic and projected data
historic_key   <- names(historic_bias_corr[[1]]) %>% str_sub(1,8)
projection_key <- names(projection_bias_corr[[1]]) %>% str_sub(1,8)

# can also manufacture them since we have a thousand time checked the dates
```


### Process Historical Period Climate Quantiles

Now that all the CMIP6 data has been bias corrected using a reference climatology, we can take the bias corrected data and build arrays that capture the variability across all models by pulling out values at each time step that represent different measures of the collection. So at each cell for every time step we now take the value from whichever model represents the 5th percentile, the mean, or the 95th percentile.

```{r historic quants}

####  Historic Quantiles


# Use the time-period length (in months) to Get the mean 5th 95th at each step
historic_mean <- time_period_quantile(
  time_period = "historic",
  time_period_collection = historic_bias_corr, 
  quantile_product = "mean")



# 5th Percentile
historic_05 <- time_period_quantile(
  time_period = "historic",
  time_period_collection = historic_bias_corr, 
  quantile_product = "5th")


# 95th Percentile
historic_95 <- time_period_quantile(
  time_period = "historic",
  time_period_collection = historic_bias_corr, 
  quantile_product = "95th")



# clean up
rm(historic_bias_corr)
```


```{r, fig.height = 8}
# Plot check
par(mfrow = c(3, 1))
plot(historic_mean$X1950.01, main = "Historic Mean", col = temp_pal)
plot(historic_05$X1950.01,   main = "Historic 5th Percentile", col = temp_pal)
plot(historic_95$X1950.01,   main = "Historic 95th Percentile", col = temp_pal)
```


### Process Climate Projection Period Quantiles

Repeat what we just did for the historical periods for the future projections. At each cell for every time step get the value from whichever model represents the 5th percentile, the mean, or the 95th percentile.

```{r projection quants}

####  Projection Quantiles


# Mean
projection_mean <- time_period_quantile(
  time_period = "projection",
  time_period_collection = projection_bias_corr, 
  quantile_product = "mean")


# 5th Percentile
projection_05 <- time_period_quantile(
  time_period = "projection",
  time_period_collection = projection_bias_corr, 
  quantile_product = "5th")


# 9th Percentile
projection_95 <- time_period_quantile(
  time_period = "projection",
  time_period_collection = projection_bias_corr, 
  quantile_product = "95th")


# clean up
rm(projection_bias_corr)
```


```{r, fig.height=8}
# Plot check
par(mfrow = c(3,1))
plot(projection_mean$X2015.01, main = "Projection Mean", col = temp_pal)
plot(projection_05$X2015.01,   main = "Projection 5th Percentile", col = temp_pal)
plot(projection_95$X2015.01,   main = "Projection 95th Percentile", col = temp_pal)

```

### Assemble complete Timelines

Once the different quantiles have been run for both the historical periods and the future projections, these two periods can be joined together to create a complete stack with time from 1950-2100.

```{r}
full_5th  <- stack(stack(historic_05), stack(projection_05))
full_mean <- stack(stack(historic_mean), stack(projection_mean))
full_95th <- stack(stack(historic_95), stack(projection_95))
```


## Export Quantiles

```{r}
# Path to the bias correction folder
var_path <- paste0(cmip_path, experiment, "/BiasCorrected/EnsembleData/", pick_var,"/", pick_var)


# File Names
writeRaster(full_5th, paste0(var_path, "_GLORYs_bias_corrected_5thpercentile.grd"), overwrite = T)
writeRaster(full_mean, paste0(var_path, "_GLORYs_bias_corrected_mean.grd"), overwrite = T)
writeRaster(full_95th, paste0(var_path, "_GLORYs_bias_corrected_95thpercentile.grd"), overwrite = T)
```



`r insert_gmri_footer()`